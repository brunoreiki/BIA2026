a:41:{s:25:"action:explain_text:model";s:32:"Modèle d’explication de texte";s:30:"action:explain_text:model_help";s:51:"Le modèle utilisé pour expliquer le texte fourni.";s:37:"action:explain_text:systeminstruction";s:20:"Instruction système";s:42:"action:explain_text:systeminstruction_help";s:162:"Cette instruction est envoyée au modèle IA avec le prompt de l’utilisateur. Il n’est pas recommandé de la modifier, sauf si c’est absolument nécessaire.";s:26:"action:generate_text:model";s:32:"Modèle de génération de texte";s:31:"action:generate_text:model_help";s:57:"Le modèle utilisé pour générer la réponse textuelle.";s:38:"action:generate_text:systeminstruction";s:20:"Instruction système";s:43:"action:generate_text:systeminstruction_help";s:162:"Cette instruction est envoyée au modèle IA avec le prompt de l’utilisateur. Il n’est pas recommandé de la modifier, sauf si c’est absolument nécessaire.";s:27:"action:summarise_text:model";s:28:"Modèle de résumé de texte";s:32:"action:summarise_text:model_help";s:50:"Le modèle utilisé pour résumer le texte fourni.";s:39:"action:summarise_text:systeminstruction";s:20:"Instruction système";s:44:"action:summarise_text:systeminstruction_help";s:162:"Cette instruction est envoyée au modèle IA avec le prompt de l’utilisateur. Il n’est pas recommandé de la modifier, sauf si c’est absolument nécessaire.";s:17:"custom_model_name";s:28:"Nom de modèle personnalisé";s:15:"enablebasicauth";s:36:"Activer l’authentification basique";s:20:"enablebasicauth_help";s:68:"Activer l’authentification basique pour le fournisseur API Ollama.";s:8:"endpoint";s:24:"Point de terminaison API";s:13:"endpoint_help";s:54:"Le point de terminaison API du fournisseur API Ollama.";s:11:"extraparams";s:28:"Paramètres supplémentaires";s:16:"extraparams_help";s:176:"Des paramètres supplémentaires peuvent être configurés ici. Le format JSON est pris en charge. Par exemple :
<pre>
{
    "temperature": 0.5,
    "max_tokens": 100
}
</pre>";s:11:"invalidjson";s:23:"Chaîne JSON non valide";s:8:"password";s:12:"Mot de passe";s:13:"password_help";s:59:"Le mot de passe utilisé pour l’authentification basique.";s:10:"pluginname";s:22:"Fournisseur API Ollama";s:16:"privacy:metadata";s:75:"Le plugin Fournisseur API Ollama n’enregistre aucune donnée personnelle.";s:50:"privacy:metadata:aiprovider_ollama:externalpurpose";s:312:"Ces informations sont envoyées à l’API Ollama afin de générer une réponse. Les réglages de votre compte Ollama peuvent modifier la façon dont Ollama enregistre et conserve ces données. Aucune donnée personnelle n’est envoyée explicitement à Ollama ou enregistrée par Moodle au moyen de ce plugin.";s:40:"privacy:metadata:aiprovider_ollama:model";s:47:"Le modèle utilisé pour générer la réponse.";s:45:"privacy:metadata:aiprovider_ollama:prompttext";s:63:"Le prompt saisi par l’utilisateur pour générer la réponse.";s:8:"settings";s:9:"Réglages";s:13:"settings_help";s:99:"Ajuster les réglages ci-dessous pour personnaliser comment les requêtes sont envoyées à Ollama.";s:17:"settings_mirostat";s:8:"Mirostat";s:22:"settings_mirostat_help";s:174:"Mirostat est un algorithme neuronal de décodage de texte permettant de contrôler la perplexité. 0 = désactvé, 1 = Mirostat, 2 = Mirostat 2.0 (réglage par défaut : 0).";s:13:"settings_seed";s:6:"graine";s:18:"settings_seed_help";s:202:"Définit la graine aléatoire utilisée pour la génération. Si la graine est définie avec un nombre déterminé, le modèle générera un même texte pour un même prompt (réglage par défaut : 0).";s:20:"settings_temperature";s:12:"température";s:25:"settings_temperature_help";s:205:"La température détermine si la réponse sera plus aléatoire et créative ou au contraire plus prédictible. En augmentant la température, on rend le modèle plus créatif (réglage par défaut : 0.8).";s:14:"settings_top_k";s:5:"top_k";s:19:"settings_top_k_help";s:210:"Réduit la probabilité de générer des absurdités. Une valeur élevée (p.ex. 100) donnera des réponses plus diverses, alors qu’une valeur basse (p.ex. 10) sera plus prudente (réglage par défaut : 40).";s:14:"settings_top_p";s:5:"top_p";s:19:"settings_top_p_help";s:223:"En combinaison avec top_k. Une valeur élevée (p.ex. 0.95) donnera des réponses plus diverses, alors qu’une valeur plus basse (p.ex. 0.5) générera un texte plus focalisé et plus prudent (réglage par défaut : 0.9).";s:8:"username";s:19:"Nom d’utilisateur";s:13:"username_help";s:64:"Le nom d’utilisateur utilisé par l’authentification basique";}